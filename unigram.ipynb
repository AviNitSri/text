{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk import PorterStemmer  \n",
    "import re\n",
    "from nltk import FreqDist\n",
    "from nltk.probability import LidstoneProbDist, WittenBellProbDist\n",
    "import sys\n",
    "from IPython.display import display\n",
    "#sys.stdout = stdout\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "stopWord = set(sw.words(\"english\"));\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "import math\n",
    "import os\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"ray_913742943690653739_cf.txt\", \"ray_925987435331224445_cf.txt\", \n",
    "        \"ray_925987537478928034_pf.txt\"]\n",
    "lam = 0.3\n",
    "topNRDoc = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "short = {\"n't\":\"not\"}\n",
    "def getwords(doc):\n",
    "    w = doc.split(' ')\n",
    "    nw = w[:]\n",
    "    for i in range (len(w)):\n",
    "        col = w[i].find(\"\\'\")\n",
    "        l = len(w[i]);\n",
    "        if l - col == 2:\n",
    "            ss = nw[i][col:];\n",
    "            if ss in short:\n",
    "                ss = short[ss]\n",
    "            nw.append(nw[i][col-1:])\n",
    "            nw[i] = nw[i][:col-1]\n",
    "    sent = \" \".join(nw);\n",
    "    return sent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = ['.', ',', '!', '', \"+\", \"#\", \"(\", \")\", \":\", \"'s\"]\n",
    "slangs = {\"n't\":\"not\", \"r\": \"are\", \"u\": \"you\"}\n",
    "def goclean(doc):\n",
    "    doc = doc.lower()\n",
    "    #\\W+\n",
    "    tokens = wt(doc)#getwords(doc)#re.findall('\\w+', doc)\n",
    "    filterWord = [];\n",
    "    \n",
    "    for w in tokens:\n",
    "        if w not in dots:\n",
    "            if w in slangs:\n",
    "                w = slangs[w];\n",
    "            filterWord.append(w)\n",
    "    sents = \" \".join(filterWord)\n",
    "    filterWord = re.findall('\\w+', sents)\n",
    "    ps = PorterStemmer()\n",
    "    stemed = []\n",
    "    for w in filterWord:\n",
    "        stemed.append(ps.stem(w)) \n",
    "    return stemed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getprobability(cleanW):\n",
    "    myarray = np.asarray(cleanW)\n",
    "    ue, ce = np.unique(myarray, return_counts=True)\n",
    "    tc = len(cleanW);\n",
    "    n = float(tc)\n",
    "    \n",
    "    p = [];\n",
    "    for i in range(len(ce)): \n",
    "        p.append(ce[i]/n)\n",
    "    \n",
    "    mydict = dict(zip(ue, p))\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(probd, probc, lam):\n",
    "    dict2 = dict(probc)\n",
    "    \n",
    "    for key, items in probc.iteritems():\n",
    "        if key in probd:\n",
    "            val = (1 - lam)*probd[key] + lam*probc[key];\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "        \n",
    "        else:\n",
    "            val = lam*(probc[key]);\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "    return dict2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpratio(probd, probc, lam):\n",
    "    dict2 = dict(probc)\n",
    "    \n",
    "    for key, items in probc.iteritems():\n",
    "        if key in probd:\n",
    "            val = ((1 - lam)*probd[key])/(lam*probc[key]) + 1;\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "        \n",
    "        else:\n",
    "            val = lam*(probc[key]);\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "    return dict2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLdivergence(q, df):\n",
    "    x = [0]*td;\n",
    "    for word, prob in q.iteritems():\n",
    "        if word not in pdf.index:\n",
    "            continue;\n",
    "        for i in range(td):\n",
    "            name = 'probd' + str(i)\n",
    "            x[i] = x[i] - prob*(math.log(pdf[name][word]))\n",
    "    return x;       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\n",
    "def getdoc(files, doc):\n",
    "    for f in files:\n",
    "        doc += open(f , 'r').read()\n",
    "    return doc\n",
    "\n",
    "doc += getdoc(files, doc);\n",
    "doc = doc.decode('utf-8');\n",
    "cw = goclean(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "probc = getprobability(cw)\n",
    "dict2 = dict(probc)\n",
    "pdf = pds.DataFrame(dict2.values(), index=dict2.keys(), columns=[\"probc\"])\n",
    "pdf[\"probc\"][\"1\"]\n",
    "tc = len(probc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = doc.split(\"\\n\")\n",
    "td = len(reviews)\n",
    "for i in range(len(reviews)):\n",
    "    name = \"probd\" + str(i);\n",
    "    clrev = goclean(reviews[i])\n",
    "    prob = getprobability(clrev)\n",
    "    ps = getpratio(prob, probc, lam)\n",
    "    pdf[name] = ps.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Very clear voice and content is good.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q = (reviews[16] + '.')[:-1]\n",
    "q = raw_input()\n",
    "cq = goclean(q)\n",
    "qprob = getprobability(cq)\n",
    "div = KLdivergence(qprob, pdf)\n",
    "index = div.index(min(div))\n",
    "reviews[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top N Relevent reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1) Very clear voice and content is good.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'2) Voice was clear and concise from a tone perspective.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'3) Good voice inflection. Good example of recommendation, relating to ML.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'4) Use of examples and cases, length okay, clear voice, closing'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'5) Good effort Lisa! Good voice projection. You will get better with more practices.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'6) Very enjoyable use of voice and tone and engaging delivery. Hit all of the key messages and core points and value prop from the script.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u\"7) Pace and varied voice inflection helps keep the attention of the audience. Clearly didn't feel rushed, which made it easy to follow. Good use of example use cases.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u\"8) You're a credible and engaging speaker great voice dynamics, facial expressions, cadence. Your delivery helps make the content seem accessible, simple, understandable. Content was complete. Thank you for your second effort on this!!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'9) Enjoyed your passion in your voice for AWS Ml. Very simple, clean to understand. Liked how you referred to ML in their daily life like \"cashier-less grocery shopping\". Liked that you emphasized our desire to give everyone a choice.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u\"10) You're a credible and engaging speaker excellent pacing, voice dynamics, etc. Love that you included stat re: number of Amazonians working on ML (100K), in addition to tenure (20 yrs). Good frame up of the three layers, and explanations of each.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tlist = div[:];\n",
    "x = []#*topNRDoc\n",
    "for i in range(topNRDoc):\n",
    "    least = min(tlist)\n",
    "    if least == 0:\n",
    "        break\n",
    "    index = tlist.index(least);\n",
    "    x.append(index)\n",
    "    tlist[index] = float(\"inf\")\n",
    "    \n",
    "rdl = len(x)\n",
    "if rdl == 0:\n",
    "    print(\"No relevent document found\")\n",
    "    \n",
    "else:\n",
    "    prt = \"\"\n",
    "    for i in range(topNRDoc):\n",
    "        display(str(i+1) + ') ' + reviews[x[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
