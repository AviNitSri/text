{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk import PorterStemmer  \n",
    "import re\n",
    "from nltk import FreqDist\n",
    "from nltk.probability import LidstoneProbDist, WittenBellProbDist\n",
    "import sys\n",
    "from IPython.display import display\n",
    "#sys.stdout = stdout\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "stopWord = set(sw.words(\"english\"));\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "import math\n",
    "import os\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"ray_913742943690653739_cf.txt\", \"ray_925987435331224445_cf.txt\", \n",
    "        \"ray_925987537478928034_pf.txt\"]\n",
    "lam = 0.3\n",
    "topNRDoc = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "short = {\"n't\":\"not\"}\n",
    "def getwords(doc):\n",
    "    w = doc.split(' ')\n",
    "    nw = w[:]\n",
    "    for i in range (len(w)):\n",
    "        col = w[i].find(\"\\'\")\n",
    "        l = len(w[i]);\n",
    "        if l - col == 2:\n",
    "            ss = nw[i][col:];\n",
    "            if ss in short:\n",
    "                ss = short[ss]\n",
    "            nw.append(nw[i][col-1:])\n",
    "            nw[i] = nw[i][:col-1]\n",
    "    sent = \" \".join(nw);\n",
    "    return sent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = ['.', ',', '!', '', \"+\", \"#\", \"(\", \")\", \":\", \"'s\"]\n",
    "slangs = {\"n't\":\"not\", \"r\": \"are\", \"u\": \"you\"}\n",
    "def goclean(doc):\n",
    "    doc = doc.lower()\n",
    "    #\\W+\n",
    "    tokens = wt(doc)#getwords(doc)#re.findall('\\w+', doc)\n",
    "    filterWord = [];\n",
    "    \n",
    "    for w in tokens:\n",
    "        if w not in dots:\n",
    "            if w in slangs:\n",
    "                w = slangs[w];\n",
    "            filterWord.append(w)\n",
    "    sents = \" \".join(filterWord)\n",
    "    filterWord = re.findall('\\w+', sents)\n",
    "    ps = PorterStemmer()\n",
    "    stemed = []\n",
    "    for w in filterWord:\n",
    "        fword = ps.stem(w)\n",
    "        stemed.append(fword) \n",
    "    return stemed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getprobability(cleanW):\n",
    "    myarray = np.asarray(cleanW)\n",
    "    ue, ce = np.unique(myarray, return_counts=True)\n",
    "    tc = len(cleanW);\n",
    "    n = float(tc)\n",
    "    \n",
    "    p = [];\n",
    "    for i in range(len(ce)): \n",
    "        p.append(ce[i]/n)\n",
    "    \n",
    "    mydict = dict(zip(ue, p))\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(probd, probc, lam):\n",
    "    dict2 = dict(probc)\n",
    "    \n",
    "    for key, items in probc.iteritems():\n",
    "        if key in probd:\n",
    "            val = (1 - lam)*probd[key] + lam*probc[key];\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "        \n",
    "        else:\n",
    "            val = lam*(probc[key]);\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "    return dict2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change in formula instead of smoothing we get prob ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpratio(probd, probc, lam):\n",
    "    dict2 = dict(probc)\n",
    "    \n",
    "    for key, items in probc.iteritems():\n",
    "        if key in probd:\n",
    "            val = ((1 - lam)*probd[key])/(lam*probc[key]) + 1;\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "        \n",
    "        else:\n",
    "            val = 1\n",
    "            #pdf[name][key] = val;\n",
    "            dict2[key] = val\n",
    "    return dict2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordMap(clrev, wordMap, i):\n",
    "    for key in clrev:\n",
    "        wordMap[key].append(i)\n",
    "    return wordMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging wordMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMerge(wordMap, word):\n",
    "    docList = []\n",
    "    for w in word:\n",
    "        if w not in pdf.index:\n",
    "            continue;\n",
    "        docList= list(set(docList + wordMap[w]))\n",
    "    return docList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLdivergence(q, df, docList):\n",
    "    TD = len(docList)\n",
    "    x = [0]*TD;\n",
    "    for word, prob in q.iteritems():\n",
    "        if word not in pdf.index:\n",
    "            continue;\n",
    "        for i in range(TD):\n",
    "            name = 'probd' + str(docList[i])\n",
    "            x[i] = x[i] + prob*(math.log(pdf[name][word]))\n",
    "    return x;       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working on collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\n",
    "def getdoc(files, doc):\n",
    "    for f in files:\n",
    "        doc += open(f , 'r').read()\n",
    "    return doc\n",
    "\n",
    "doc += getdoc(files, doc);\n",
    "doc = doc.decode('utf-8');\n",
    "cw = goclean(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "probc = getprobability(cw)\n",
    "dict2 = dict(probc)\n",
    "pdf = pds.DataFrame(dict2.values(), index=dict2.keys(), columns=[\"probc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = len(probc)\n",
    "values = [[] for _ in range(tc)]\n",
    "keys = dict2.keys()\n",
    "wordMap = dict(zip(keys, values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = doc.split(\"\\n\")\n",
    "td = len(reviews)\n",
    "for i in range(len(reviews)):\n",
    "    name = \"probd\" + str(i);\n",
    "    \n",
    "    clrev = goclean(reviews[i]) # ['what', 'should', 'not', 'be', 'done'] without removing stopword\n",
    "    \n",
    "    wordMap = getWordMap(clrev, wordMap, i) #{u'andra': [1084, 1084], u'authorit': [254, 255, 784, 254, 255, 784],.....}\n",
    "    \n",
    "    prob = getprobability(clrev) #{'be': 0.20000000000000001,'done': 0.20000000000000001,........}\n",
    "    \n",
    "    ps = getpratio(prob, probc, lam) #((1 - lam)*probd[key])/(lam*probc[key]) + 1;\n",
    "    \n",
    "    pdf[name] = ps.values() #including the doc model in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Good job!'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q = (reviews[16] + '.')[:-1]\n",
    "q = raw_input() # \"what shouldn't be done\"\n",
    "\n",
    "cq = goclean(q) # ['what', 'should', 'not', 'be', 'done'] without removing stopword\n",
    "#display(cq)\n",
    "qprob = getprobability(cq) #{'be': 0.20000000000000001,'done': 0.20000000000000001,........}  \n",
    "#display(qprob)\n",
    "docList = getMerge(wordMap, cq) #[1195, 4, 519, 522, 524, .......] list containg words in query\n",
    "#display(docList)\n",
    "div = KLdivergence(qprob, pdf, docList) #ranking function using KL divergens\n",
    "#display(div)\n",
    "index = div.index(max(div)) #most probabel relevent doc\n",
    "\n",
    "reviews[docList[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top N Relevent reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1) Good job!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'2) Good job'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'3) Good presentation, good job!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'4) good job Gina!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'5) Good job Tim !'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'6) Nice sound. Good job!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'7) Great presentation, good job Matt !'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'8) Good job like the personalization!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'9) Good job. Easy to engage style.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "u'10) Good job keeping length around 5mins!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tlist = div[:];\n",
    "x = []#*topNRDoc\n",
    "\n",
    "for i in range(min(topNRDoc, len(tlist))):\n",
    "    Pmax = max(tlist)\n",
    "    #if least == 0:\n",
    "        #break\n",
    "    index = tlist.index(Pmax);\n",
    "    x.append(docList[index])\n",
    "    tlist[index] = -1;\n",
    "\n",
    "    \n",
    "rdl = len(x)\n",
    "if rdl == 0:\n",
    "    print(\"No relevent document found\")\n",
    "    \n",
    "else:\n",
    "    prt = \"\"\n",
    "    for i in range(rdl):\n",
    "        display(str(i+1) + ') ' + reviews[x[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
